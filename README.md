# Proyecto de Procesamiento de Datos a Gran Escala

Este repositorio contiene el desarrollo de un proyecto analÃ­tico basado en la metodologÃ­a CRISP-DM para el procesamiento de datos de gran escala, orientado a resolver preguntas de negocio en entornos educativos utilizando herramientas de Big Data.

## ğŸ“Œ **Objetivos del Proyecto**

- Comprender la importancia de las herramientas de Big Data en entornos empresariales y su capacidad para resolver problemas de negocio.
- Aplicar la metodologÃ­a CRISP-DM para la elaboraciÃ³n de proyectos analÃ­ticos y generar hallazgos de valor en el anÃ¡lisis de datos.
- Documentar la implementaciÃ³n de un cluster como infraestructura para procesar grandes volÃºmenes de datos, utilizando mÃ¡quinas virtuales.
- Realizar procesamiento de datos y generar resultados aplicados a un problema real relacionado con el sector educativo.

---

## ğŸ“Œ **MetodologÃ­a CRISP-DM**

El proyecto se ejecuta utilizando la metodologÃ­a CRISP-DM (Cross-Industry Standard Process for Data Mining) para realizar un anÃ¡lisis completo de los datos y responder a las preguntas de negocio planteadas.

### Fases del Proyecto

1. **Entendimiento del Negocio y de los Datos (Entrega 1)**  
   - ContextualizaciÃ³n del problema y objetivos de negocio.
   - SelecciÃ³n y anÃ¡lisis de los conjuntos de datos proporcionados.
   - ExploraciÃ³n, limpieza, transformaciÃ³n y generaciÃ³n de preguntas de negocio para abordar en la segunda entrega.

2. **PreparaciÃ³n de Datos, Modelado y PresentaciÃ³n de Resultados (Entrega 2)**  
   - RealizaciÃ³n de filtros y transformaciones adicionales en los datos.
   - Respuesta a las preguntas de negocio mediante anÃ¡lisis y visualizaciÃ³n de datos.
   - AplicaciÃ³n de tÃ©cnicas de aprendizaje automÃ¡tico (supervisado y no supervisado).
   - ImplementaciÃ³n de los modelos en el entorno Databricks y cluster Apache Spark.

---

## ğŸš€ **TecnologÃ­as y Herramientas Utilizadas**

- **Databricks**: Plataforma unificada para el anÃ¡lisis y procesamiento de datos.
- **Apache Spark**: Motor de procesamiento distribuido utilizado para trabajar con grandes volÃºmenes de datos.
- **Python**: Lenguaje principal para la manipulaciÃ³n y anÃ¡lisis de datos.
- **MLlib**: LibrerÃ­a de aprendizaje automÃ¡tico de Apache Spark.

---

## ğŸ“Š **Estructura del Proyecto**

1. **Entrega 1: Entendimiento del Negocio y de los Datos**
   - AnÃ¡lisis de los datos del servicio de internet por municipio, pobreza, ICFES y niveles de educaciÃ³n.
   - ExploraciÃ³n estadÃ­stica de los datos, reporte de calidad y generaciÃ³n de preguntas de negocio.

2. **Entrega 2: PreparaciÃ³n de Datos, Modelado y Respuesta a las Preguntas**
   - TransformaciÃ³n y limpieza de los datos.
   - AplicaciÃ³n de tÃ©cnicas de aprendizaje supervisado y no supervisado.
   - EvaluaciÃ³n de los resultados y respuesta a las preguntas de negocio planteadas.

---

## ğŸ¥· **Colaboradores**
- **[Juan Pablo Arias](https://github.com/JuanParias29/Perfil_GitHub)**
- **[Paula Andrea Romero](https://github.com/Andyy870)**
- **[Juan AndrÃ©s Lopez](https://github.com/usuario)**   
- **[Kevin](https://github.com/usuario)** 
- **[Juan JosÃ©](https://github.com/usuario)**

---
## ğŸ“…**Curso**
**Procesamiento de Datos a Gran Escala**  
ğŸ“ *Pontificia Universidad Javeriana*  
ğŸ‘¨â€ğŸ« *Docente:* [John Corredor, PhD](https://github.com/corredor-john)

Â¡Bienvenido a este desafÃ­o en el mundo del procesamiento de datos a gran escala! ğŸš€
