# Proyecto de Procesamiento de Datos a Gran Escala

Este repositorio contiene el desarrollo de un proyecto analítico basado en la metodología CRISP-DM para el procesamiento de datos de gran escala, orientado a resolver preguntas de negocio en entornos educativos utilizando herramientas de Big Data.

## 📌 **Objetivos del Proyecto**

- Comprender la importancia de las herramientas de Big Data en entornos empresariales y su capacidad para resolver problemas de negocio.
- Aplicar la metodología CRISP-DM para la elaboración de proyectos analíticos y generar hallazgos de valor en el análisis de datos.
- Documentar la implementación de un cluster como infraestructura para procesar grandes volúmenes de datos, utilizando máquinas virtuales.
- Realizar procesamiento de datos y generar resultados aplicados a un problema real relacionado con el sector educativo.

---

## 📌 **Metodología CRISP-DM**

El proyecto se ejecuta utilizando la metodología CRISP-DM (Cross-Industry Standard Process for Data Mining) para realizar un análisis completo de los datos y responder a las preguntas de negocio planteadas.

### Fases del Proyecto

1. **Entendimiento del Negocio y de los Datos (Entrega 1)**  
   - Contextualización del problema y objetivos de negocio.
   - Selección y análisis de los conjuntos de datos proporcionados.
   - Exploración, limpieza, transformación y generación de preguntas de negocio para abordar en la segunda entrega.

2. **Preparación de Datos, Modelado y Presentación de Resultados (Entrega 2)**  
   - Realización de filtros y transformaciones adicionales en los datos.
   - Respuesta a las preguntas de negocio mediante análisis y visualización de datos.
   - Aplicación de técnicas de aprendizaje automático (supervisado y no supervisado).
   - Implementación de los modelos en el entorno Databricks y cluster Apache Spark.

---

## 🚀 **Tecnologías y Herramientas Utilizadas**

- **Databricks**: Plataforma unificada para el análisis y procesamiento de datos.
- **Apache Spark**: Motor de procesamiento distribuido utilizado para trabajar con grandes volúmenes de datos.
- **Python**: Lenguaje principal para la manipulación y análisis de datos.
- **MLlib**: Librería de aprendizaje automático de Apache Spark.

---

## 📊 **Estructura del Proyecto**

1. **Entrega 1: Entendimiento del Negocio y de los Datos**
   - Análisis de los datos del servicio de internet por municipio, pobreza, ICFES y niveles de educación.
   - Exploración estadística de los datos, reporte de calidad y generación de preguntas de negocio.

2. **Entrega 2: Preparación de Datos, Modelado y Respuesta a las Preguntas**
   - Transformación y limpieza de los datos.
   - Aplicación de técnicas de aprendizaje supervisado y no supervisado.
   - Evaluación de los resultados y respuesta a las preguntas de negocio planteadas.

---

## 🥷 **Autor**
- **[Juan Pablo Arias](https://github.com/JuanParias29/Perfil_GitHub)**

---
## 📅**Curso**
**Procesamiento de Datos a Gran Escala**  
📍 *Pontificia Universidad Javeriana*  
👨‍🏫 *Docente:* [John Corredor, PhD](https://github.com/corredor-john)

¡Bienvenido a este desafío en el mundo del procesamiento de datos a gran escala! 🚀
